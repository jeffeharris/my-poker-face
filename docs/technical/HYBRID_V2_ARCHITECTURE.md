---
purpose: Architecture design for the two-phase hybrid AI decision + character expression system
type: design
created: 2026-02-12
last_updated: 2026-02-13
---

# Hybrid V2: Decision + Character Architecture

## Core Principle

**The option menu IS the strategy.** The rule engine encodes poker knowledge into bounded options. The LLM picks from those options (cheap, fast, reliable). A separate character layer turns that pick into a dramatic moment. The player's personality, emotional state, and hand plan create narrative tension — not poker math.

## Architecture Overview

```
Hand Start
  │
  ├── Phase 0: HAND STRATEGY (once per hand)
  │     Inputs: cards, position, stack, reads, emotional state
  │     Output: 1-2 sentence plan (stored as string)
  │     Cost: ~100 tokens in, ~20 out
  │     Memory: cleared after generation
  │
  ├── Phase 1: LEAN DECISION (per street, stateless)
  │     Inputs: plan text + options with EV labels
  │     Output: {"choice": N}
  │     Cost: ~150 tokens in, ~15 out
  │     Memory: cleared before each call
  │
  └── Phase 2: CHARACTER EXPRESSION (separate, future)
        Inputs: decision, strategy, context
        Output: dramatic_sequence, monologue
        Cost: ~300 tokens in, ~80 out
```

## Glossary

| Term | Definition |
|---|---|
| **option profile** | The `OptionProfile` thresholds that control option generation (fold_equity_multiplier, raise_neutral, etc.). Mapped from personality via looseness + aggression. |
| **style hint** *(deprecated)* | The old static one-liner injected into the lean prompt (e.g., "Play aggressively"). Replaced by the hand plan. |
| **hand plan** | Phase 0 output — the AI's 1-2 sentence approach for the current hand, based on cards, position, mood. Injected as a "Plan:" line in each Phase 1 user message. |
| **option menu** | The 2-4 bounded options generated by the rule engine for a given decision point. |
| **EV label** | The `+EV` / `neutral` / `-EV` tag on each option in the menu, derived from equity vs pot odds. |
| **character thread** | The Phase 2 conversation history, separate from the decision calls. Contains dramatic expressions and character continuity within the hand. |

## What Drives What

### Personality Anchors → Option Profile (static per game)

Looseness + aggression from personality config determine the base option profile:

| Looseness | Aggression | Profile | Effect on Options |
|-----------|------------|---------|-------------------|
| < 0.45 | < 0.5 | tight_passive | Fewer calls, fold offered more, smaller bets |
| < 0.45 | >= 0.5 | tight_aggressive | Fewer calls, raises with bigger sizing |
| 0.45-0.65 | any | default | Current balanced behavior |
| > 0.65 | < 0.5 | loose_passive | More calls, fold blocked more, smaller bets |
| > 0.65 | >= 0.5 | loose_aggressive | More raises, bigger sizing, bluff frequency |

### Emotional State → Profile Modifier (dynamic per hand)

Emotional state shifts the effective looseness/aggression, which can push a player into a different profile zone:

- **Tilted**: looseness increases → options become looser (more calls, fewer folds)
- **Scared/low energy**: looseness decreases → options tighten up
- **Confident**: aggression increases → bigger sizing, more raise options
- **On tilt + confident**: the most dangerous — loose AND aggressive

This means the same player gets different option menus depending on their emotional state. Napoleon on tilt sees even more aggressive options than calm Napoleon.

### Hand Plan → Decision Bias + Narrative Thread

At the start of each hand, the AI formulates a hand plan based on:
- Hole cards + position
- Stack depth (SPR considerations)
- Opponent reads (from opponent model)
- Current emotional state
- Active style profile

The plan is 1-2 sentences, something like:
- "Strong hand in position — bet for value on every street, build the pot"
- "Marginal hand but good position — see a cheap flop, fold to aggression"
- "Short stack, need to pick a spot — if I connect on the flop, I'm going all-in"

**Key design change (v2):** The hand plan is injected as a `Plan:` line in each Phase 1 user message. Memory is cleared before every decision — no conversation accumulation.

The original v1 design kept the plan in the conversation history ("decision thread"). Experiments 113841-113842 showed this fails with gpt-5-nano: accumulated conversation history (10-14 messages by the turn) causes the model to anchor on prior conservative choices, reducing post-flop raise rates from ~46% to ~17% regardless of plan content. The plans themselves were aggressive ("pressure", "c-bet", "extract value") but the model picked check 66% of the time with long context.

The v2 approach gives Phase 1 exactly 3 things: the plan text, the current situation, and the options. Each decision is stateless.

**Why not static style hints?** Experiment 113836-113838 showed that style hints ("Play aggressively") override EV labels and produce degenerate behavior (100% VPIP, 91% raise rate). Even softened hints ("Lean aggressive — respect the math") had minimal effect (96% VPIP). Removing hints entirely and fixing fold EV labels brought Napoleon to 64% VPIP / 37% raise — but at the cost of losing post-flop personality differentiation. The hand plan replaces the style hint with something contextual and per-hand: "fold this junk" for 7-2 offsuit, "raise for value" for pocket aces.

### Plan vs Reality → Drama

The bounded options naturally create plan deviations. If Napoleon planned to c-bet aggressively but the board comes Ace-high with a flush draw and he has pocket 7s, the options won't include big raises. His character expression can now reference the deviation:

- Inner monologue: "This wasn't the flop I wanted. Retreat."
- Dramatic sequence: *studies the board carefully* "...check."

Conversely, if the plan WAS to trap and the opponent bets into a monster, the options will show +EV calls and raises. The character knows this aligns with the plan:

- Inner monologue: "Perfect. They walked right into it."
- Dramatic sequence: *barely suppresses a smile* "I'll call."

## Phase 0: Hand Plan

### When It Fires
- Once at the beginning of each hand (before first decision)
- Uses the lean system prompt style (minimal tokens)
- Response lands in the decision thread

### Inputs
```
Cards: Ah Kd
Position: Button
Stack: 45 BB | Opponents: 3
Reads: Player2 raises 60% preflop, Player3 folds to c-bets
Mood: Confident

Plan your approach for this hand in 1-2 sentences.
```

### Output
```json
{"strategy": "Premium hand on the button — raise preflop for value, c-bet any flop, pressure Player3 who folds to aggression."}
```

### How It's Used
- Generated once at hand start, stored as a string (`_current_hand_plan`)
- Injected as a `Plan:` line in each Phase 1 user message
- Conversation memory is cleared after Phase 0 and before each Phase 1 call
- Phase 2 (character thread) receives the hand plan as an input separately

### Phase 1 Prompt with Plan

Each Phase 1 decision is stateless — the LLM sees only the plan, current situation, and options:

```
Cards: Ah Kd | Board: Qs 7h 2c
Stack: 42 BB | Pot: 9.0 BB
Plan: Premium hand on the button — raise for value, c-bet any flop.

1. CHECK  [marginal]  Check (strong hand - consider betting for value)
2. RAISE 3BB  [+EV]  Value bet (65% equity)
3. RAISE 6BB  [+EV]  Strong value bet (65% equity)

Pick 1-3: {"choice": N}
```

Token budget per decision: ~150 tokens in, ~15 out. Plan adds ~20-30 tokens per decision.

**Why not keep the plan in conversation history?** Experiments 113841-113842 tested the "decision thread" approach where Phase 0 + all Phase 1 exchanges accumulated in conversation memory. With gpt-5-nano, this caused:
- Post-flop raise rates dropped from ~46% to ~17% (both players)
- The model anchored on prior `{"choice": 1}` responses (usually check/call)
- By the turn, 10-14 messages of context degraded decision quality
- Napoleon became LESS aggressive than Bob Ross despite aggressive plans

The stateless approach gives Phase 1 clean context every time.

### Strategic Context by Playstyle

Phase 0 injects playstyle-specific strategic context into the hand plan prompt. The active playstyle determines what information the AI sees when formulating its plan. This reuses the existing briefing system from `playstyle_selector.py`.

#### Playstyle → Info Matrix

| Playstyle | Approach | Stats/Tips Provided | What's Suppressed |
|---|---|---|---|
| guarded | Defensive, pot control | Pot as % of stack, who is aggressive | Pot odds (full engagement) |
| poker_face | GTO, math-driven | Pot in BB, equity | Opponent emotion (full engagement) |
| commanding | Exploitative, controlled | Stack leverage, SPR, who is weak | Nothing suppressed |
| aggro | Exploitative, brash | Target name + weakness summary | Equity verdict + pot odds (full engagement) |
| base | Neutral fallback | Positions, stacks | Nothing |

#### Engagement Tiers

Engagement is determined by the raw Gaussian affinity of the active playstyle (from `playstyle_selector.py`):

| Tier | Affinity | Phase 0 Context |
|---|---|---|
| Basic | < 0.25 | Cards, position, stack, opponents only |
| Medium | 0.25 – 0.55 | + Mindset frame + risk stance + exploit tips |
| Full | > 0.55 | + Curated stats + suppressions active |

At basic engagement, the hand plan prompt is purely situational — no personality-driven info. At full engagement, the AI sees curated stats tailored to its playstyle and opponent-aware exploit tips.

#### Emotional Modifiers

Emotional state indirectly affects Phase 0 quality through the playstyle selection system:

- **Overconfident** (high confidence, low composure): May land in aggro zone, suppressing equity info → plans are more aggressive, less informed
- **Tilt** (low composure): Flat softmax temperature → chaotic style selection → plans may not match the player's natural style
- **Overheated** (high energy, low composure): Skews toward aggressive zone affinity → plans favor aggression even when defensive play is better

These effects emerge from the existing psychology system — Phase 0 doesn't add new emotional logic.

#### Implementation

Reuses existing functions from `poker/playstyle_selector.py`:
- `_build_stat_lines()` — curated stats per playstyle (stack leverage for commanding, pot % for guarded, etc.)
- `build_exploit_tips()` — opponent-aware actionable tips (e.g., "Player2 folds to c-bets 70%")
- `MINDSET_FRAMES` — per-style strategic framing ("You have leverage. Extract maximum value.")
- `_select_biggest_threat()` — identifies the most aggressive opponent for exploit targeting

Phase 0 prompt with strategic context (full engagement, commanding style):
```
Cards: Ah Kd
Position: BTN
Stack: 45 BB | Opponents: 3
Stack leverage: 1.3x table average. SPR is 8.2 — room for multi-street value.
Player3 is passive — bet thin for value, they won't raise without the nuts.

Plan this hand in 1 sentence.
{"plan": "..."}
```

Phase 0 prompt at basic engagement (no strategic context):
```
Cards: 7s 2h
Position: UTG
Stack: 22 BB | Opponents: 4

Plan this hand in 1 sentence.
{"plan": "..."}
```

## Phase 1: Lean Decision

Rule engine generates the option menu, LLM picks one. The hand plan is injected as a `Plan:` line in the user message. Each decision is stateless (memory cleared).

```
Cards: Ah Kd | Board: Qs 7h 2c
Stack: 43 BB | Pot: 6.0 BB
Plan: Premium hand on the button — raise for value, c-bet any flop.

1. CHECK  [marginal]  Check (strong hand - consider betting for value)
2. RAISE 2BB  [+EV]  Value bet (65% equity)
3. RAISE 4BB  [+EV]  Bet for value (65% equity)
4. RAISE 6BB  [+EV]  Strong value bet (65% equity)

Pick 1-4: {"choice": N}
```

## Phase 2: Character Expression (Separate Conversation)

Phase 2 uses the **character thread**, separate from the decision thread. This prevents dramatic narration from polluting future Phase 1 decisions and keeps the decision thread clean (just hand plan + option menus + choices).

### Two Threads Per Hand

```
Decision thread (Phase 0 + Phase 1):
  [user]  "Cards: Ah Kd | Position: BTN | Stack: 45BB. Plan?"
  [asst]  {"plan": "Raise for value, c-bet any flop."}
  [user]  "1. RAISE 3BB [+EV] ... Pick 1-3:"
  [asst]  {"choice": 1}
  [user]  "Board: Qs 7h 2c ... 1. CHECK [marginal] ... Pick 1-4:"
  [asst]  {"choice": 2}

Character thread (Phase 2, separate):
  [user]  "You are Napoleon. Plan: 'Raise for value, c-bet any flop.'
           You just chose: RAISE 4BB (+EV). Board: Qs 7h 2c.
           This aligns with your plan. Express your reaction."
  [asst]  {"dramatic_sequence": ["*surveys the table*", "Four big blinds."]}
```

Phase 2 receives the hand plan and decision as inputs but lives in the character thread. This means:
- Phase 1 never sees dramatic text in the decision thread
- Phase 2 can accumulate its own character continuity within the hand
- Different models can be used (cheap/fast for Phase 1, expressive for Phase 2)

### When It Fires
- After every Phase 1 decision
- Can be skipped for routine hands (drama level = routine) to save tokens

### Inputs
```
You are Napoleon at the poker table. You are confident and commanding.

Hand strategy: "Premium hand on the button — raise preflop for value, c-bet any flop."
You just chose: RAISE 4BB (value bet, +EV)
Board: Qs 7h 2c | Your hand: Ah Kd
This aligns with your plan.

Express your reaction in character. Be brief for routine moments, dramatic for big ones.
```

### Output
```json
{
  "inner_monologue": "The board missed everyone. Time to apply pressure as planned.",
  "dramatic_sequence": ["*surveys the table with authority*", "Four big blinds."],
  "hand_strategy_update": null
}
```

### Drama Scaling
- **Routine**: 1 beat — a gesture or brief action, no speech required
- **Notable**: 1-2 beats
- **High stakes**: 2-3 beats, reference the plan
- **Climactic**: 3-5 beats, full character moment, plan-vs-reality tension

## Design Decisions

### Phase 0: Always On, Togglable

**Decision:** Always run Phase 0. Make it togglable via PromptConfig for A/B testing.

Phase 0 fires at the start of each hand, before the first action. Every hand gets a strategy — even if that strategy is "fold this junk." The plan creates the narrative thread that Phase 2 references.

Why not skip for weak hands? Even a fold decision has character value: "Not my hand — wait for a better spot" vs "I'd normally fold this but I'm tilted and want action." The strategy captures *intent*, which is what makes the character feel alive.

For hands on the outer edges of the range (barely playable), the strategy is especially interesting — that's where personality matters most. A tight player's strategy for 9-7 suited is "fold unless I'm on the button with passive opponents." A loose player's strategy for the same hand is "see a cheap flop, chase the straight draw."

### Hand Plan Delivery: Decision Thread → Stateless Injection

**v1 Decision (rejected):** The hand plan lives in the decision thread as the LLM's own prior output, not as a "Plan:" line injected into Phase 1 prompts.

The original reasoning: keeping Phase 1 "pure" (no plan context, just EV labels) didn't work — all players converge to the same post-flop behavior. Style hints failed — the LLM treats them as overrides. The decision thread approach was designed to solve both:
- The hand plan biases decisions without an explicit instruction (it's the LLM's own prior thought)
- Multi-street context emerges naturally (the LLM sees its preflop raise when deciding the flop)
- Per-hand, per-card, per-mood — not a static label

**v1 Result (experiments 113841-113842):** Failed. Conversation memory accumulation caused gpt-5-nano to anchor on prior conservative choices. Post-flop raise rates dropped from 46% to 17%. Plans were aggressive but selections were not. See Experiment Log for full data.

**v2 Decision (current):** Plan generated once, stored as string, injected as `Plan:` line in each Phase 1 user message. Memory cleared before every decision. Each Phase 1 call is stateless — no conversation history between streets.

### Strategy Updates: Fixed for Now, Wire Later

**Decision:** Strategy is fixed at preflop. No mid-hand revisions for v1.

The case for mid-hand updates is strong (all-in moments, board texture shifts), but it adds complexity and token cost. The option menu already handles the mechanical adaptation — when the plan falls apart, the options change naturally. Phase 2 can reference the *deviation* from the hand plan without needing an explicit update.

We'll wire in a `plan_update` field in Phase 2's output schema so it's ready when we want it. For now, Phase 2 ignores it.

### Phase 2: Chattiness + Expressiveness Gate

**Decision:** Most decisions get Phase 2, but chattiness and expressiveness control the output volume.

No hard skip based on drama level. Instead:
- **Low expressiveness**: Phase 2 returns a physical action only (*slides chips forward*) — no speech
- **High expressiveness**: Full dramatic sequence with speech
- **Chattiness**: Controls whether table talk appears, independent of actions
- **Drama level**: Scales the beat count (1 for routine, 3-5 for climactic)

This means even a silent, stoic player gets *something* on every decision — a gesture, a glance, a movement. The character is always present, just at different volumes.

### Emotional State: Between Hands Only

**Decision:** Option profile is locked for the duration of a hand. Emotional state shifts only affect the next hand.

Psychology already updates via `on_action_taken()` after each action, but the profile mapping only re-evaluates at hand start. This keeps decision-making predictable within a hand — you don't suddenly get looser options on the river because you tilted on the turn.

The emotional state DOES flow into Phase 2 (character expression) mid-hand. So a player can *show* tilt in their expressions even though their options haven't changed yet. The tilt affects their next hand's options.

### Latency: Separate Calls, Sequential, Accepted

**Decision:** Phase 0, Phase 1, and Phase 2 use separate conversations and can use different models. All calls for a given decision must complete before the game advances.

Phase 0 fires once per hand. Phase 1 and Phase 2 fire per street. Table talk from one player feeds into the next player's context.

| Component | Tokens Out | Estimated Latency | Frequency |
|-----------|-----------|-------------------|-----------|
| Phase 0 (hand plan) | ~20 | ~400ms | Once per hand |
| Phase 1 (lean decision) | ~15 | ~800ms | Per street |
| Phase 2 (character, stoic) | ~15 | ~200ms | Per street |
| Phase 2 (character, dramatic) | ~80 | ~600ms | Per street |

For a 4-player hand (3 AIs) going to showdown (~4 streets, ~12 decisions):
- Phase 0: 3 × ~400ms = **~1.2s** (once per hand)
- Phase 1 + Phase 2: ~12 × ~1.2s = **~14.4s**
- **Total: ~15.6 seconds per hand**
- Old system: ~12 decisions × ~2.4s = ~29 seconds per hand
- Still roughly 2x faster, with better output + character expression

The natural latency lever is expressiveness. Quiet players produce fewer Phase 2 tokens. Phase 2 can also be skipped for routine moments.

## Open Questions

### Post-Flop Profile Differentiation
- After LAG tuning, profiles differentiate well preflop (Napoleon 78% VPIP vs Bob Ross 56%) but converge post-flop (both ~37-40% raise rate)
- Phase 0 strategy should address this — the strategy biases post-flop picks based on the plan
- If Phase 0 doesn't fully solve post-flop convergence, consider profile-specific post-flop thresholds (separate `raise_neutral` for preflop vs post-flop)

### Memory Clearing in Lean Mode (resolved → reverted)
- v1: when `hand_plan` enabled, memory clears once at hand start and persists within the hand
- v1 result: conversation accumulation caused conservation bias with gpt-5-nano (experiments 113841-113842)
- **v2: memory clears before every decision regardless of hand_plan setting.** Plan injected as text, not conversation history.

### Hand Plan vs EV Label Precedence (partially resolved)
- v1 (decision thread): the plan was overwhelmed by accumulated context — the model ignored its own plan and anchored on prior choices
- v2 (stateless injection): the plan competes only with the EV labels in a single message — cleaner signal
- Still an empirical question whether the plan meaningfully biases selection away from EV labels

### Remaining Style Hints (tight_passive, loose_passive)
- LAG style hint was removed, but tight_passive and loose_passive still have style hints
- These are less problematic (tight hints don't cause degenerate play like aggressive ones did)
- When `hand_plan` is enabled, the hand plan replaces style hints — no static hint is injected
- tight_passive and loose_passive hints are preserved as fallback when `hand_plan` is disabled
- If Phase 0 proves effective in experiments, remove all style hints entirely

### Fold EV Labels + Noisy Equity
- The fold EV fix (fold labeled `[+EV]` when equity is well below required) applies globally
- Preflop equity estimates are coarse buckets, not precise calculations
- Combined with tight option profiles (higher fold_equity_multiplier), this could cause over-folding in edge cases
- Monitor tight_passive fold rates after Phase 0 experiments

### Phase 2 Model Choice

**Decision:** Start with Groq Llama 8B. Groq's inference speed (~200 tokens/s) keeps Phase 2 latency minimal. Mistral 3B is a fallback if 8B is overkill for short dramatic sequences. Both are essentially free compared to OpenAI models.

## Experiment Log

### LAG Tuning (experiments 113836 → 113838)

| Experiment | Changes | Napoleon VPIP | Fold | Raise |
|---|---|---|---|---|
| 113836 (baseline) | Original LAG profile + aggressive hint | 100% | 0% | 91% |
| 113837 (tuned v1) | fold_mult 1.5→1.8, raise_neutral 0.35→0.42, softened hint | 96% | 2% | 79% |
| 113838 (tuned v2) | + fold EV fix (fold labeled +EV when correct), hint removed | 64% | 7% | 37% |

Key findings:
1. **Style hints are toxic** — the LLM treats them as overrides, not nudges
2. **Fold EV labels matter enormously** — labeling fold as `-EV` when equity < required was backwards (folding saves money = correct play). Fixing this to `+EV` was the single biggest improvement
3. **Option profiles alone aren't enough for post-flop differentiation** — all players converge when looking at the same EV-labeled option menu
4. **Hand plan is the right replacement for style hints** — per-hand, per-card, personality-driven

### Phase 0 Hand Plan v1: Decision Thread (experiments 113839 → 113842)

**Design:** Plan lives in conversation history. Memory cleared once at hand start, preserved within hand. Phase 1 sees Phase 0 + all prior street decisions.

| Experiment | Changes | Napoleon Post-Flop Raise | Bob Ross Post-Flop Raise | Gap |
|---|---|---|---|---|
| 113839 | Missing `enable_psychology` — plans at basic engagement | — | — | Generic, both passive |
| 113840 | Added `enable_psychology: true` but missing `update_playstyle()` | — | — | Still basic engagement |
| 113841 | Fixed `update_playstyle()` at hand start. Strategic context appears. | 20.3% | 25.4% | **-5.1pp** (wrong direction) |
| 113842 | Added mindset frame at all engagement tiers + playstyle cues | 17.0% | 23.2% | **-6.2pp** (wrong direction) |
| *(control)* | lean-no-plan (style-aware options, no hand plan) | 46.2% | 39.7% | **+6.5pp** (correct) |

Key findings:
1. **Conversation memory accumulation kills aggression** — by the turn, 10-14 messages in context. Napoleon post-flop raise dropped from 46% to 17%. Both players shifted from raise-first to check-first.
2. **The plans themselves were aggressive** — 100% of Napoleon's plans contained aggressive language ("pressure", "c-bet", "extract value"). The content wasn't the problem.
3. **gpt-5-nano anchors on prior conservative choices** — the model sees its own `{"choice": 1}` (usually check/call) in history and repeats the pattern.
4. **Playstyle election works** — Napoleon got commanding/aggro 59% of the time vs Bob Ross 29%. The problem was delivery mechanism, not personality mapping.
5. **Same options, radically different selection** — when raise was available post-flop, no-plan Napoleon picked raise 47% of the time; with plan, only 16%. Options were identical.

**Conclusion:** The decision thread approach fails with small models. Pivoting to stateless injection — plan text in the Phase 1 user message, memory cleared every decision.

### Phase 0 Hand Plan v2: Stateless Injection (experiment 113843)

**Design:** Plan generated once at hand start, stored as string, injected as `Plan:` line in each Phase 1 user message. Memory cleared before every decision. Each Phase 1 call sees only: plan + situation + options.

```
Cards: Ah Kd | Board: Qs 7h 2c
Stack: 42 BB | Pot: 9.0 BB
Plan: Premium hand on the button — raise for value, c-bet any flop.

1. CHECK  [marginal]  Check (strong hand - consider betting for value)
2. RAISE 3BB  [+EV]  Value bet (65% equity)
3. RAISE 6BB  [+EV]  Strong value bet (65% equity)

Pick 1-3: {"choice": N}
```

**Hypothesis:** Stateless injection avoids the context accumulation problem while still providing personality-driven decision bias.

| Experiment | Napoleon Post-Flop Raise | Bob Ross Post-Flop Raise | Gap |
|---|---|---|---|
| 113843 (stateless injection) | 67.6% | 67.5% | **+0.1pp** (no differentiation) |
| *(control)* | 43.2% | 33.6% | **+9.6pp** (correct) |

**Result:** Fixed the conservation bias but created the opposite problem. Both players generate aggressive plans (99-100% contain aggressive language regardless of personality framing), so both get pushed to ~67.5% raise rate. The plan text overrides EV labels — same failure mode as the original style hints, just with more tokens.

### Conclusion: Hand Plan Approach Abandoned

Three delivery mechanisms tested, none produced better differentiation than the control:

| Approach | Napoleon | Bob Ross | Gap | Failure Mode |
|---|---|---|---|---|
| **No plan (control)** | **43.2%** | **33.6%** | **+9.6pp** | — |
| v1: plan in conversation history | 17.0% | 23.2% | -6.2pp | Memory accumulation → conservative anchor |
| v2: plan in user message | 67.6% | 67.5% | +0.1pp | Plan overrides EV labels → both aggressive |

The fundamental issue: gpt-5-nano generates aggressive poker plans for ALL personalities. Mindset frames ("Control the pot") and playstyle cues ("You play cautiously") are not strong enough to overcome the model's default "play aggressive poker" bias. The plan text then acts as either a suppressor (v1, via context overload) or an override (v2, via direct injection).

**Style-aware option profiles remain the best differentiator.** The +9.6pp gap comes entirely from different option menus (loose_aggressive vs tight_passive profiles), not from LLM personality expression. Future differentiation work should focus on the option generation layer, not prompt-level personality injection.

## Status

### Done
- [x] OptionProfile dataclass with 10 threshold params
- [x] 5 STYLE_PROFILES presets (tight_passive, tight_aggressive, default, loose_passive, loose_aggressive)
- [x] Parameterized option generation functions
- [x] Looseness + aggression → profile mapping
- [x] style_aware_options flag for A/B testing
- [x] Experiment validation (47pp VPIP spread)
- [x] Personality anchor seeding fix
- [x] LAG profile tuning (fold_equity_multiplier, raise thresholds)
- [x] Fold EV label fix (fold labeled +EV when folding is correct)
- [x] Removed LAG style hint (to be replaced by hand plan)
- [x] Phase 0: `hand_plan` toggle on PromptConfig + Phase 0 generation in HybridAIController
- [x] Per-hand memory clearing (v1: clear at hand start, preserve within hand)
- [x] Playstyle-aware Phase 0 prompts (strategic context varies by engagement tier + active playstyle)
- [x] Mindset frame at all engagement tiers (not just medium+)
- [x] Playstyle plan cues ("You play aggressively for maximum value.")
- [x] Opponent model wiring into Phase 0 (exploit tips from `_select_biggest_threat()`)
- [x] Phase 0 prompt capture tagging (`prompt_template='hand_plan'`)
- [x] Style hint suppression when hand_plan enabled (plan replaces static hints)
- [x] Experiment config: `experiments/configs/hand_plan_test.json` (A/B: plan vs no-plan)
- [x] Experiments 113839-113842: v1 decision thread approach tested and rejected
- [x] Experiment 113843: v2 stateless injection tested and rejected
- [x] **Hand plan approach abandoned** — style-aware options alone give best differentiation

### Next
- [ ] Improve post-flop differentiation via option generation layer (profile-specific post-flop thresholds)
- [ ] Phase 2: Character expression prompt (design + implement)
- [ ] Chattiness/expressiveness gating for Phase 2 output volume
- [ ] Wire emotional state → looseness modifier between hands
- [ ] Experiment: full pipeline test (decision + character) vs current system
